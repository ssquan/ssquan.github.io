'use strict';(function(){const indexCfg={};indexCfg.doc={id:'id',field:['title','content'],store:['title','href'],};const index=FlexSearch.create(indexCfg);window.geekdocSearchIndex=index;index.add({'id':0,'href':'/post/','title':"Posts",'content':""});index.add({'id':1,'href':'/','title':"Quan's Blog",'content':""});index.add({'id':2,'href':'/post/spark-operator-bad-certificate/','title':"Spark Operator 密钥问题",'content':" 这个是一个由问题推动的知识点收集的旅程，记录了问题本身和问题的定位 (Google) 的点滴。在解决问题时，尝试去 Dive Deeper，就会有一些乐趣产生。\n你也许刚好没有接触这块的知识点，对，刚好。没有关系，我尝试输出的是一种定位和解决问题的快乐方法。\n 背景 你听过 Spark， Maybe 听过 Spark on K8S，但是 Almost not 听过 Spark Operator。Just Remember 这个是个车厂多于轮胎厂的时代，组合创新盛行而有效。Spark Operator 就是 Google Cloud Native 方式在 K8S 上运行 Spark 的组装车。 不多说，上车。\n现象 在升级 Spark Operator 后遇到了 Spark Application 无法解析 HDFS namenode service name，报 \u0026quot;Unknown Host\u0026quot; 的错误。前方说我们 十万火急，需要立刻解决，不解决就影响项目进度了。耳熟？对，我们遇到的问题 4 个 9 以上面的话结尾。First，calm down。\n线索  从表象上看，最直接的问题是在 Spark Driver 中没有 HDFS 的配置文件： hdfs-site.xml； 从 Pod 的信息中可以看到 HDFS 配置 Volume 未挂载； 查看 Spark Operator 的 Log，有一行可疑信息\u0026quot;Bad Certificate\u0026quot; 。  信息 因为 \u0026quot;Bad Certificate\u0026quot; 能给我们的信息可能很关键，但是并不直观，没有直接说明是谁和谁之间通信的证书不对，所以本次定位是采用从 Volume 挂载的地方入手。平常喜欢的方式是 从现象到理论到代码 的方式进行递进。先顺着线索收集了相关的理论信息。\n1. Mounting volume Spark Operator 的说明文档中有指出Mounting volume 需要Enable webhook，这个点比较难找。https://github.com/GoogleCloudPlatform/spark-on-k8s-operator/blob/master/docs/user-guide.md#mounting-volumes\n检查了下当前的环境，Webhook 已经 Enable，存在 Spark Operator Controller (CRD) 中。如果不是专业的 K8S 运维，比较难理解 Mutating admission webhook 的含义，嘿，刚好我不是，那就继续挖呗。\n2. Mutating admission webhook 这个概念属于 K8S 的范畴，这张图说明了 Mutating Admission Webhook 插件化应用的位置。\n直观来说：在 Api server 收到 API 请求后，可以在这个 Hook 点进行一些特殊化的改写动作。Spark Operator 就是在这个点挂载 HadoopConfiguration。当 Api Server 访问 Mutating Admission Webhook 时需要采用 Https 方式进行访问，也就是在此处用到了认证信息。\n图片来源于这片对 Admission Webhook 的介绍：https://kubernetes.io/blog/2019/03/21/a-guide-to-kubernetes-admission-controllers/, （敲黑板，贴出来原链接的意思就是值得看）。\n在K8S中，Service Account 通常我们只能使用公钥，如果自定义服务之间需要访问，就需要自己生成密钥对、创建 K8s Secret，这个过程在 Spark-web-hook-init 中调用源码里面 hack 目录下的脚本完成。\n3. Web-hook-init 从这个 Job 的 yaml 文件中可以看到，在早期的版本中干的事情是清除密钥和创建密钥。但是遇到了 Update 会清除密钥但不创建新密钥的问题，后面就将这两个功能拆分成两个 yaml。见 issues： https://github.com/GoogleCloudPlatform/spark-on-k8s-operator/issues/875\n很可惜，这个问题和我们遇到的问题还不一样，并不能拿来就用，美梦没有得逞。\n猜测 从现象和前面收集的信息来看，最大的可能是 Web-hook-init 产生的密钥并没有更新到 Spark Api Server。很大的可能性是升级是先升级了 Spark-operator 的 API Server，然后重新执行了web-hook-init。基于原理的猜想，大概不那么玄学了吧，有效驳斥了老程序定位问题的直觉说。\n验证 即然是顺序问题，那么我们重启 Spark-operator 服务，功能正常。嗯，对，还是重启大法好啊。说的没错，同时咱们是有理有据的重启。\nDeeper 我起初怀疑是我们内部没有采用 Helm 部署导致的问题，翻开 Yaml 却发现并没有关于 Install Order 的控制，Helm 的默认控制顺序和预期的不一样，Deployment 先部署，Secret 后部署。\nhttps://github.com/helm/helm/blob/release-2.10/pkg/tiller/kind_sorter.go#L61\nTrust me，Coder 很难信服非标操作但是理论上Ok的这种东西，大概率还是会保持怀疑，It\u0026rsquo;s OK。\n思考 为什么部署的时候没事，反而 update 的时候有事呢？。这里有关于如果pod 创建时， Secret 还没有创建是如何运作的介绍。\nhttps://kubernetes.io/docs/concepts/configuration/secret/\n也就是说如果 Secret 的创建在 Pod 的创建之后是没事的。那么更新是如何运作的呢？\n在上面的 Note 中已经说明了 Update 对 Spark Operator 这种将 Secret mount 到 Pod 中的玩法无效。具体的Mount 方式是在 spark-operator-deployment.yaml 中控制的：\n{{ toYaml .Values.imagePullSecrets | trim | indent 8 }} {{- if .Values.enableWebhook }} volumes: - name: webhook-certs secret: secretName: spark-webhook-certs {{- end }} 为什么 helm update 没事，自己update 服务有事呢？\n这个纯粹和我们 Update 的方式相关，操作人员在 Update 前执行了 Delete 操作。理论上 K8S 走的是**Volidate - Diff - Apply **的操作模式，只会更新 Diff 的地方。单纯的 Update 是不会更新 Secret 的。\n所以，包含这么多知识点的一个问题，归根到底却是一个操作问题。又有什么关系呢？又收获就 OK了。\n后记 我是个经常救火，又立志决不当 Fire man 的人，所以保持借假修真的心态，探究的更加深入，找出知识点和乐趣。\n提前祝各位Coder 中秋快乐。\n"});index.add({'id':3,'href':'/post/presto-insert-mysql/','title':"Presto导出数据到Mysql",'content':"故事的开始 一个咖啡劲儿已经消退了的午后，业务大大突然笑眯眯的对我说: \u0026ldquo;Presto insert Mysql 特别慢，跑了几十分钟了，一直 13% 左右， 你，帮忙看看？\u0026quot;。第一反应就是: \u0026ldquo;嗯？难道出大问题了？\u0026quot;，老实讲，有一点点小兴奋。\n一顿操作猛如虎 紧接着，大概进行了如下几个猛如虎的操作：\n Presto 监控看起来，嗯～有一个 Stage 很慢，但是又没有死，大概十几K Row/s 的速度在爬行； Mysql 监控看起来，哦？CPU 低很，内存不大，磁盘占用率和 IO 都不高，网络更别说了，不忙； Presto 进程在搞啥这么慢？Jstack 一下，stack 就是在 write 的地方，没毛病； Mysql 的信息再稍微捞一捞。  果然不出所料，并没那么 easy 就看到原因，再来一杯咖啡提提神吧。\n来自大自然的猜想 提神醒脑之后开始整理思路（\u0026amp; YY）。基本确定的是：\n 两个系统都没有发生什么异常，他们在正常的工作，只是慢； 资源不紧张，看起来不是瓶颈，深度怀疑是有竞争了。  难道是有锁竞争？Show Create Table 还真有一点小小的惊喜，内容是这样的（ 已脱敏）：\n| mock_id_cross_index | CREATE TABLE `mock_id_cross_index` ( `id` bigint(20) DEFAULT NULL, `c1` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci NOT NULL , `c2` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci DEFAULT NULL, `c3` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci NOT NULL, `c4` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci DEFAULT NULL, `c5` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci DEFAULT NULL, `c6` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci DEFAULT NULL, `c7` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci DEFAULT NULL, `c8` bigint(20) DEFAULT NULL, PRIMARY KEY (`c1`), KEY `AK_c1` (`c2`) USING BTREE, KEY `AK_c2` (`c3`) USING BTREE, KEY `AK_c3` (`c4`) USING BTREE, KEY `AK_c4` (`c5`) USING BTREE, KEY `AK_c5` (`c6`) USING BTREE 先卖个关子，不说明这里主要的坑。但是满眼的索引很可疑。\n探一探 InnoDB 的状态 查看 InnoDB 状态后，居然没有看到想象中的锁竞争 。想想我们的数据是预先去重的，所以理论也并不会竞争 Insert Lock。这里稍微贴一下 InnoDB 的事物信息（已裁减无用信息 \u0026amp; 脱敏 \u0026amp; 不看也没关系）：\n------------ TRANSACTIONS ------------ ---TRANSACTION 2820204, ACTIVE 0 sec 1 lock struct(s), heap size 1136, 0 row lock(s), undo log entries 327 MySQL thread id 99133, OS thread handle 139965631731456, query id 107575094 100.64.22.0 root starting INSERT INTO `studydb`.`tmp_presto_509cb3802fc84d6697019cad2c55c982` (`c1`, `c2`, `c3`) VALUES ('37008735_xxxx','717460_R0073xxx','717xxx') ---TRANSACTION 2820201, ACTIVE 0 sec 1 lock struct(s), heap size 1136, 0 row lock(s), undo log entries 457 MySQL thread id 99138, OS thread handle 139965657954048, query id 107575093 100.64.22.0 root init INSERT INTO `studydb`.`tmp_presto_509cb3802fc84d6697019cad2c55c982` (`c1`, `c2`, `c3`) VALUES ('35922969_xxx_xxx','21918025_Q1829xxx','21918xxx') ---TRANSACTION 2820200, ACTIVE 0 sec inserting 发现没有 Lock Waiting 后是有点迷茫的，干脆来个笨办法吧。对比了有索引和没有索引下的 innodb 的状态， 发现了一些有用的信息。（右图是有索引）\n从上面的对比看，有几点的差异比较明显（无索引 vs 有索引）：\n Modified db pages，45594 vs 127588， meaning 有索引时修改的 Page 页比较多； writes/s， 210 vs 1474 ，meaning 有索引时每秒改写的 Page 数增了不少； youngs/s 和 non-youngs/s 的速度，0 vs 1467 \u0026amp; 5996，meaning 有索引时导致 Page 在 young 和 non-young 之间转换频繁。  到这里，我们可以将慢的原因范围限定了，是什么东西导致了频繁的 Page 操作。再回顾下创表语句。哦，是它：\n C1 是自建字符串类型的主键索引\n 主键索引的自建绝对是 Performance killer，Btree 结构的情况下，据我不多的 DB 知识，Page 里面都是要排序的。\n赶紧验证自己的猜想，删除 C1 的主键索引，采用自增 Primary Key 后测试，完美。世界又恢复了美好。\nPresto Insert Mysql 的流程 严格意义上来说，属于创建表的 DDL 有问题，但是 Presto 作为一个框架，兼容性要强。来看看 Presto 是如何写 Mysql 数据的。Presto 通过先将数据写入临时表的方式达到了 Atom 的效果，具体流程如下：\nsequenceDiagram participant presto_coordinator participant presto_worker participant Mysql presto_coordinator -\u0026gt;\u0026gt; Mysql: 1. Create temporary table presto_coordinator -\u0026gt;\u0026gt; presto_worker: 2. Write temp table presto_worker -\u0026gt;\u0026gt; Mysql: 3. Insert into temp table presto_coordinator -\u0026gt;\u0026gt; Mysql: 4.Insert into select from temporary table presto_coordinator -\u0026gt;\u0026gt; Mysql: 5. Delete temporary table 文字版说明：\n 在 Presto Coordinator 解析作业时如果发现是 Insert 操作，则创建一个临时表； Presto Worker 上开始运行作业，读取数据，写入数据； Presto Coordinator 在数据写完后，执行 SQL 将数据从临时表拷贝到目标表； Presto Coordinator 删除临时表；  临时表的做法带来了原子性，也伴随着两个问题，稍微列一列不多说：\n 写放大，整个过程，Mysql 需要至少 2 倍于数据量的空间； 临时表有些情况会被残留，必现的场景是执行操作过程中 Mysql 发生重启；  社区贡献 明白 Presto 的 insert 流程后，基本有了一个思路：在创建临时表的时候不要索引，先写了临时表，然后通过 INSERT SELECT 的模式将数据倒腾到目标表。然后去社区一顿忽悠，搞了个 Issues 上去了。\n截图上有一个细节，这个 Issues 是 22 day ago 的。Presto 的代码严谨程度应该是 Top 级的，在提交 Pull request 的时候 Reviewer 就敏锐的发现了 CREATE TABLE AS SELECT 在 GTID 模式下不支持，并且这个人马上去补充了一堆 GTID 的测试用例，花了不少时间等这个测试用例。代码和评论也是扣的很细，20 天后才 Merged。具体细节琐碎而丢人，我就不放出来了，有兴趣的可以去看 PR 共勉。\n后记 本质上来说是表结构设计问题，很遗憾没有第一时间发现，当然发现了也就没有这么长的故事了。\nPR 的改法严格来说并不完美，因为误伤的约束检查会很多，有不少可以在插入临时表的时候就做掉，比如 Primary key 的 Unique 检查。单纯过滤掉 Primary Key 的做法应该是更好的，只是代码逻辑上会繁杂一点点。\n其实，整个过程并没有如上面的操作般行云流水，研究了不少 Mysql 的锁机制和 SHOW ENGINE INNODB STATUS\\G的输出信息，反复准备环境和验证。\n祝大家中秋快乐！！\n"});index.add({'id':4,'href':'/post/data-governace/','title':"数据治理",'content':"数据治理的建设难点 Meta data 元数据是数据资产的基石，元数据的几层认知：\n Data Catalog Data Lineage  典型的开源系统：Apache Atlas，依赖的核心技术是 存储关系的图数据库 和 支持数据检索的数据库，例如 Hbase\n数据安全 数据安全问题涉及到认证、鉴权、脱敏（Data Mask）等问题。常见的实施位置：\n 查询层，是在查询层进行屏蔽，其灵活性比在存储层屏蔽高。 存储层，如果是特别敏感，任何用户，甚至数据开发不可见的信息可以在存储成就进行脱敏；  脱敏的难点：\n 在大文本内容中进行脱敏，这种模式的粒度比基于字段的粒度要高，例如要在大文本中脱敏掉姓名。   Data Quality 数据质量有大的质量体系，各行业也有具体的标准，质量保证、质量控制体系的建设需要注意的是保留开放性，能方便的进行增强和修改。\nData Asset 数据知产的关键核心在于能体现数据的价值，数据成本和核算暂时没有看到相关的建设，还处于理论层面。有很多数据资产的产品实际是在体现业务层的元数据，行业内的数据资产个人观点是需要更多时间沉淀。\n数据治理的大数据知识 围绕数据治理的各部分内容，梳理其对数据存储和检索的需求场景。\nApache Ranger 作为数据安全领域的开源组件，提供基于 \u0026ldquo;Resource-User-Operation\u0026rdquo; 三者的权限定义模式，加上权限 ACL 的方式实现权限控制。特点：\n ACL 采用黑白名单结合的方式进行定义，可以灵活选择是白名单优先还是黑名单优先； 基于 Resource 资源的鉴权可以同步到 Resource 侧进行 Cache，单 Resource 只需要关注自己资源对应的权限，是一种Cache 策略，也会带来Cache 策略的缓存同步问题； Audit 审计功能，提供了类似 Solr，Hdfs 等方式，其主要的模式就是将日志写入到分布式存储 or 本地文件，不会回送给Admit； 根据用户查询权限的方式会有查询性能不高，内部用户场景应该是已经基本适用了。 支持数据脱敏  思考；\n 相比于 Sql Gateway 的单输入点控制模式，其架构复杂，但是可以从原理侧防止开发人员直接访问引擎，数据是否对开发可见是鉴权设计需要考虑的点； 公有云的 AK 模式鉴权，似乎是完全基于 DB 的认证服务模式，会有性能瓶颈么？  Apache Atlas 数据血缘的重要组件，以插件化图数据库和元数据库的TiTan为核心，提供的核心功能：\n 数据 Tagging，可以给数据打多个标签，用来做数据分类。 标签可以基于血缘进行传递； 标签系统可以和 Apache Ranger 进行结合，； 支持数据脱敏 Mask 和审计功能；  可以看到 Apache Atlas 和 Apache Ranger 在审计和脱敏的功能上有重叠。\nBI 建设难点：\n BI 的系统会影响到DW/DM 的Schema 设计，比如我们想分析手术类型对住院日期的影响，那么如果手术类型是被包含在手术记录中的一段文本就很难去做BI，需要独立抽取出来形成一个字段。 领域性比较强的行业，For instance，医疗行业，还没有形成统一的数仓 Schema，各家的玩法都不一样，并且 Schema 的设计很多是有行业专家进行主导，这样 Schema 的设计和实际的 BI 需求之间就会有 Gap。  标签系统 难点： 建设方针： 和实时数仓的关系\n数据质量 机器学习在数据质量里面的应用\n模型机服务？模型和代码的服务 "});index.add({'id':5,'href':'/categories/','title':"Categories",'content':""});index.add({'id':6,'href':'/tags/','title':"Tags",'content':""});})();